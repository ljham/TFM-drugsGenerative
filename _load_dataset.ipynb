{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Instalar librerias y dependencias necesarias para el proyecto","metadata":{"_uuid":"1214c24d-61a6-49c3-9f01-8f64ea8bf938","_cell_guid":"c58da273-a7f0-4634-8938-c45961873e26","trusted":true}},{"cell_type":"code","source":"!pip install python-dotenv --upgrade\n!pip install boto3 --upgrade\n!pip install pyaml --upgrade\n!pip install Jinja2 --upgrade\n!pip install opensearch-py\n!pip install tqdm","metadata":{"_uuid":"2576ee77-4514-4b16-9571-fb89b6366283","_cell_guid":"f9970e65-bcd7-4b85-b0e7-80376748b3b8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-30T03:53:20.202373Z","iopub.execute_input":"2024-07-30T03:53:20.203690Z","iopub.status.idle":"2024-07-30T03:55:05.066734Z","shell.execute_reply.started":"2024-07-30T03:53:20.203646Z","shell.execute_reply":"2024-07-30T03:55:05.065159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importar librerias y dependencias","metadata":{"_uuid":"52696b4f-7290-4dd9-8da9-402193864edd","_cell_guid":"0d4007de-62ad-4bec-9733-6ccf77064d43","trusted":true}},{"cell_type":"code","source":"import os\nimport sys\nimport logging\nimport boto3\nimport botocore\nimport yaml\nimport json\nimport requests\nimport zipfile\n\nfrom tqdm import tqdm\nfrom typing import Callable\nfrom time import time, sleep\n\nfrom jinja2 import Template, Environment\nfrom dotenv import load_dotenv, find_dotenv\nfrom opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\nfrom opensearchpy.helpers import bulk, streaming_bulk\n\n# Configurar el logging\nlogging.basicConfig(level=logging.DEBUG, \n                    format='%(asctime)s - %(levelname)s - %(message)s',\n                    datefmt='%Y-%m-%d %H:%M:%S',\n                    handlers=[\n                        logging.FileHandler(\"drugs.log\"),\n                        logging.StreamHandler()\n                    ]\n                   )","metadata":{"_uuid":"53bdd9d4-63a7-49d2-8735-4dded3b50158","_cell_guid":"a0166f78-4923-42b3-ab62-3554640348a8","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T04:59:27.624531Z","iopub.execute_input":"2024-07-30T04:59:27.625118Z","iopub.status.idle":"2024-07-30T04:59:27.635923Z","shell.execute_reply.started":"2024-07-30T04:59:27.625078Z","shell.execute_reply":"2024-07-30T04:59:27.634600Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cargar variables de entorno y archivos de configuración","metadata":{"_uuid":"55dd8662-9ad8-49a0-9c74-94a37afc823d","_cell_guid":"69beded7-719b-4a0f-a1d3-e8e361262846","trusted":true}},{"cell_type":"code","source":"# Carga variables entorno y archivos de configuración\nif not(load_dotenv(find_dotenv())):\n    sys.exit('No se puede continuar porque no se han definido las variables de entorno para el  proyecto!')\n        \n# Cargar archivo de configuraciones .yaml\ntry:\n    # Definir una función para cargar variables de entorno\n    def get_env_variable(name):\n        return os.getenv(name)\n\n    # Crear un entorno Jinja2 con la función de carga de variables de entorno\n    env = Environment()\n\n    # Agregar la función de entorno al entorno Jinja2\n    env.globals['env'] = get_env_variable\n\n    with open('config.yaml', 'r') as file:\n        template_content = file.read()\n    \n     # Cargar el contexto YAML\n    yaml_data = yaml.safe_load(template_content)\n    \n     # Renderizar la plantilla con el contexto\n    template = env.from_string(template_content)\n    rendered_content = template.render(**yaml_data)\n    \n    # Cargar el YAML renderizado\n    yaml_data = yaml.safe_load(rendered_content)\n    \n    print(\"Archivo de configuracion cargado exitosamente.\")\nexcept FileNotFoundError:\n    print(\"Error: El archivo de configuración .yaml no se encuentra disponible\")\nexcept yaml.YAMLError as exc:\n    print(f\"Error al analizar el archivo YAML: {exc}\")\nexcept Exception as e:\n    print(f\"Ocurrió un error inesperado: {e}\")","metadata":{"_uuid":"94f76558-f7ae-45f5-bce1-0d51df63db8b","_cell_guid":"485eccb7-1d55-41fa-853b-8ff5bdf69429","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T04:59:38.430774Z","iopub.execute_input":"2024-07-30T04:59:38.431226Z","iopub.status.idle":"2024-07-30T04:59:38.480291Z","shell.execute_reply.started":"2024-07-30T04:59:38.431193Z","shell.execute_reply":"2024-07-30T04:59:38.478274Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Valida que se hayan definido las variables de configuración y las variables de entorno\ntry:\n    # Cargar variables de entorno\n    aws_region = os.environ['aws_region']\n    aws_access_key_id = os.environ['aws_access_key_id']\n    aws_secret_access_key = os.environ['aws_secret_access_key']\n    \n    # Cargar variables de configuración\n    project = yaml_data.get('Project', {})\n    project_name = project.get('name')\n    url_dataset = project.get('url_dataset')\n    \n    open_search = yaml_data.get('OpenSearch', {}) \n    service = open_search.get('service')\n    port = open_search.get('port')\n    use_ssl = open_search.get('use_ssl')\n    verify_certs = open_search.get('verify_certs')\n    pool_maxsize = open_search.get('pool_maxsize')\n    timeout = open_search.get('timeout')\n    \n    collection_name = open_search.get('Collection',{}).get('name')\n    collection_index = open_search.get('Collection',{}).get('index')\n    collection_chunk_size = open_search.get('Collection',{}).get('chunk_size')\n   \n    if(aws_region is None):\n        raise Exception('No se ha definido la variable de entorno: aws_region')\n    elif(aws_access_key_id is None):\n        raise Exception('No se ha definido la variable de entorno: aws_access_key_id')\n    elif(aws_secret_access_key is None):\n        raise Exception('No se ha definido la variable de entorno: aws_secret_access_key')\n    if(project_name is None):\n        raise Exception('No se ha definido la variable de configuración del proyecto : project_name')\n    elif(url_dataset is None):\n        raise Exception('No se ha definido la variable de configuración del proyecto : url_dataset')\n    elif(service is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : service')\n    elif(port is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : port')\n    elif(use_ssl is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : use_ssl')\n    elif(verify_certs is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : verify_certs')\n    elif(pool_maxsize is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : pool_maxsize')\n    elif(timeout is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : timeout')\n    elif(collection_name is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : collection_name')\n    elif(collection_index is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : collection_index')\n    elif(collection_chunk_size is None):\n        raise Exception('No se ha definido la variable de configuración de openSearch-AWS : collection_chunk_size')\n    \n    # Define variables de entorno y variables globales\n    DATASET_FOLDER = project_name + '/dataset'\n    \n     # Crea directorio para almacenar los datasets\n    if not(os.path.exists(DATASET_FOLDER)):\n        !mkdir -p {DATASET_FOLDER}\n        print('Directorio creado exitosamente!!')\n    \nexcept Exception as ex:\n    print(ex)\n    print(f'Error en la linea No. {ex.__traceback__.tb_lineno}')","metadata":{"_uuid":"347f3bcb-9753-4962-9892-df42014eb09f","_cell_guid":"bf99bf16-b065-4f27-970b-035d93d66417","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T04:59:52.180243Z","iopub.execute_input":"2024-07-30T04:59:52.180785Z","iopub.status.idle":"2024-07-30T04:59:52.214967Z","shell.execute_reply.started":"2024-07-30T04:59:52.180743Z","shell.execute_reply":"2024-07-30T04:59:52.213325Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Definición de Funciones","metadata":{"_uuid":"744c4190-611b-4eae-9b5c-0724ae8b43bf","_cell_guid":"5a5b7b9a-7b90-4921-81be-d93f8fd5fd3b","trusted":true}},{"cell_type":"code","source":"#  Decorador para medir el tiempo de ejecución de la función\ndef measure_time(func:Callable)->Callable:\n    '''\n    args: one argument, is the function that we want to decorated(e,g functions that:\n    build the model, train the model, optimize the model, ...etc)\n    '''\n    # define the wrapper function that executes the original function(e,g arg func)\n    def wrapper(*args, **kwargs)->float:\n        '''\n        the wrapper function have the same argument as the object(e,g arg)function\n        '''\n        start_time=time()\n        # call the object function to process and manipulate ...\n        result=func(*args, **kwargs)\n        end_time=time()\n\n        processing_time=end_time-start_time\n        print(f'tiempo de procesamiento {processing_time:.2f} segundos')\n        return result\n\n    return wrapper\n\n# Función para validar si una URL es válida\ndef is_url_valid(url : str) -> bool:\n    try:\n        response = requests.head(url)\n        return response.status_code == 200\n    except Exception:\n        return False\n\n# Función para descargar archivos desde repositorio openFDA\n@measure_time\ndef download_files(url_file : str, chunk_size: int = 1024):\n    try:\n        # Hacer la solicitud para descargar el archivo .zip\n        response = requests.get(url_file, stream=True)\n        if(response.status_code != 200):\n            raise Exception(f\"Error en la solicitud HTTP: {url_file}| respuesta: {response.status_code}\")\n        \n        zip_filename = os.path.join(DATASET_FOLDER, url_file.split('/')[-1])\n        \n        total_size = int(response.headers.get('content-length', 0))\n        \n        # Guardar el archivo .zip descargado\n        with open(zip_filename, 'wb') as file:\n            file.write(response.content)\n            #for data in tqdm(response.iter_content(chunk_size=chunk_size), total=total_size//chunk_size, unit='KB'):\n            #    file.write(data)\n                    \n        logging.debug(\"Archivo guardado como: {}\".format(zip_filename))\n        \n        # Extraer el contenido del archivo .zip\n        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n            zip_ref.extractall(DATASET_FOLDER)\n        logging.debug(\"Archivo extraído: {}\".format(zip_filename))\n\n        # Eliminar el archivo .zip descargado\n        os.remove(zip_filename)\n        logging.debug(\"Archivo .zip eliminado {}\".format(zip_filename))\n        \n    except zipfile.BadZipFile:\n        logging.error(\"El archivo no es un archivo zip válido: {}\".format(zip_filename))\n    except FileNotFoundError:\n        logging.error(\"El archivo no fue encontrado: {}\".format(zip_filename))\n    except Exception as ex:\n        logging.error(\"Ocurrió un error al extraer el archivo {}: {}\".format(zip_filename, e))\n        \ndef get_data_drugs(json_file):\n    try:\n        if(json_file):\n            data = json.load(json_file)\n            last_updated = data['meta']['last_updated']\n            batch = []\n            \n            for item in data['results']:\n                item['last_updated'] = last_updated\n                \n                # Crear un nuevo diccionario con la estructura deseada y fusionar openfda si existe\n                results = {**{k: v for k, v in item.items() if k != \"openfda\"}, **item.get(\"openfda\", {})}\n                action = {\n                    \"_index\": collection_index,\n                    \"_id\": results['id'],  # Usar el atributo 'id' como ID del documento\n                    \"_source\": results\n                }\n                batch.append(action)\n                \n                # Si el tamaño del lote es 500, hacer yield y reiniciar el lote\n                if len(batch) == collection_chunk_size:\n                    yield batch\n                    batch = []\n            \n            if batch is not None:\n                yield batch\n        #return actions\n            \n    except Exception as ex:\n        logging.error(\"Ocurrió un error al leer los datos {} \".format(ex))\n        print(f\"Ocurrió un error al leer los datos {ex}\")\n        print(ex.__traceback__.tb_lineno)","metadata":{"_uuid":"d7b74e8c-0b4b-407b-90f9-3b21a8a977ff","_cell_guid":"14d68bae-ea17-46d8-8a51-42c2113bb260","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T05:00:03.272460Z","iopub.execute_input":"2024-07-30T05:00:03.272912Z","iopub.status.idle":"2024-07-30T05:00:03.295614Z","shell.execute_reply.started":"2024-07-30T05:00:03.272874Z","shell.execute_reply":"2024-07-30T05:00:03.294335Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descargar dataset desde OpenFDA","metadata":{"_uuid":"c3e1c367-37dd-46c6-b8f2-dac39d54d291","_cell_guid":"958f9e1d-5ecd-453c-81cf-7238f0adba1e","trusted":true}},{"cell_type":"code","source":"# Descargar dataset desde OpenFDA\ntry:\n    response = requests.get(url_dataset)\n    if(response.status_code != 200):\n        raise Exception(f\"Error en la solicitud HTTP. Código de respuesta: {response.status_code}\")\n        \n    data = response.json()\n    \n    # Obtener las particiones\n    partitions = data.get('results', {}).get('drug', {}).get('label', {}).get('partitions', [])\n\n    boo = False\n    if isinstance(partitions, list):\n        total_files = len(partitions)\n        with tqdm(total=total_files, desc=\"Procesando descarga\") as pbar:\n            for partition in partitions:\n                file_url = partition.get('file', '')\n                if file_url and is_url_valid(file_url):\n                    print(f\"Descargando archivo desde: {file_url}\")\n                    download_files(file_url)\n                    pbar.update(1)\n    else:\n        print(\"El nodo 'partitions' no es una lista.\")\n        \nexcept Exception as ex:\n    print(ex)","metadata":{"_uuid":"a2306b42-9368-41db-8997-05095ea1f545","_cell_guid":"e6e4ccf8-e182-41c2-a361-b8962bcdce44","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T03:59:38.291801Z","iopub.execute_input":"2024-07-30T03:59:38.292260Z","iopub.status.idle":"2024-07-30T04:02:07.370505Z","shell.execute_reply.started":"2024-07-30T03:59:38.292227Z","shell.execute_reply":"2024-07-30T04:02:07.368411Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cargar información al servicio de OpenSearh Serverless AWS","metadata":{"_uuid":"293a6e24-5916-43e3-8dff-e2a3cb85bcd2","_cell_guid":"79d49521-a0f5-4bd8-9708-6fd3fa6d1749","execution":{"iopub.status.busy":"2024-07-14T16:20:49.395104Z","iopub.execute_input":"2024-07-14T16:20:49.395529Z","iopub.status.idle":"2024-07-14T16:21:06.493005Z","shell.execute_reply.started":"2024-07-14T16:20:49.395495Z","shell.execute_reply":"2024-07-14T16:21:06.491496Z"},"trusted":true}},{"cell_type":"code","source":"try:\n    # Establecer conexión con OpenSearch-AWS-Serverless\n    session = boto3.Session(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name=aws_region)\n    client = session.client('opensearchserverless')\n    credentials = session.get_credentials()\n    awsauth = AWSV4SignerAuth(credentials, aws_region, service)  \n    response = client.batch_get_collection(names=[collection_name])\n    \n    #sleep(2)\n\n    # Extraer el endpoint de la colección desde el response\n    aws_host = (response['collectionDetails'][0]['collectionEndpoint'])\n    aws_host = aws_host.replace(\"https://\", \"\")\n\n    # Construir el cliente de OpenSearch\n    client = OpenSearch(hosts=[{'host': aws_host, 'port': port}],\n                        http_auth=awsauth,\n                        use_ssl=use_ssl,\n                        verify_certs=verify_certs,\n                        connection_class=RequestsHttpConnection,\n                        timeout=timeout,\n                        pool_maxize=pool_maxsize\n                        )\n    \n    # Leer archivos JSON\n    json_files = [pos_json for pos_json in os.listdir(DATASET_FOLDER) if pos_json.endswith('.json')]\n    json_files = sorted(json_files, key=lambda x: int(x.split('-')[2]))\n    print(json_files)\n    \n    # Leer el contenido de cada archivo JSON\n    data_set = []\n    if(True):\n        success = 0\n        failed = 0\n        \n        for json_file in json_files:\n            print(f'Load dataset : {json_file}')\n            with open(os.path.join(DATASET_FOLDER, json_file), 'r') as f:\n                acu = 0\n                for batch in get_data_drugs(f):\n                    # Calcular el tamaño del lote en KB\n                    batch_size = len(json.dumps(batch)) / 1024 / 1204 # Convertir el lote a JSON y medir el tamaño en MB\n                    print(f'Batch size: {batch_size:.2f} MB')\n                    acu+= batch_size\n                    if(True):\n                        responses = []\n                        for ok, response in streaming_bulk(\n                            client=client,\n                            actions=batch,\n                            chunk_size=collection_chunk_size,  # Número de documentos por cada chunk\n                            max_chunk_bytes=150 * 1024 * 1024,  # 150 MB\n                            raise_on_error=False,\n                            raise_on_exception=False,\n                            max_retries=3,\n                            initial_backoff=2,\n                            max_backoff=5,\n                            yield_ok=True,\n                            ignore_status=[409]):\n                            if ok:\n                                success += 1\n                            else:\n                                failed += 1\n                                print(response)\n\n                    # Eviar una colección de datos de forma masiva usando bulk d e OpenSearch.helper\n                    #success, failed = streaming_bulk(client, data_set)\n                    #print('=============================')\n                    #print('success : ', success)\n                    #print('failed : ', failed)\n                print(f'Total Batch size: {acu:.2f} MB')\n                acu = acu/1024\n                print(f'Total Batch size: {acu:.2f} GB')\n            break\n    \n        print(f'Successful operations: {success}')\n        if(failed > 0):\n            print(f'Failed operations: {failed}')\n            print(json.dumps(responses))\n        \n\n    # Insertar un documento en OpenSearch\n    '''\n    try:\n        for doc in data:\n            response = client.index(index=collection_index, body=doc)\n\n    except Exception as ex:\n        print(ex.error)\n    '''    \n    \nexcept Exception as ex:\n    print(f\"Ocurrió un error al procesar los archivos jsonx : {ex}\")\n    print(ex.__traceback__.tb_lineno)","metadata":{"_uuid":"2a127d6a-3bc0-4346-8b41-a7c671182473","_cell_guid":"de7f7640-dc4c-43b2-a789-64b9bb6c776d","collapsed":false,"execution":{"iopub.status.busy":"2024-07-30T05:35:25.356707Z","iopub.execute_input":"2024-07-30T05:35:25.357277Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}